{
    "name": "root",
    "gauges": {
        "CubeAgentZone.Policy.Entropy.mean": {
            "value": 1.3727473020553589,
            "min": 1.3727473020553589,
            "max": 1.4317954778671265,
            "count": 25
        },
        "CubeAgentZone.Policy.Entropy.sum": {
            "value": 2733.139892578125,
            "min": 2713.892578125,
            "max": 2912.170166015625,
            "count": 25
        },
        "CubeAgentZone.Environment.EpisodeLength.mean": {
            "value": 28.71641791044776,
            "min": 25.91891891891892,
            "max": 490.25,
            "count": 25
        },
        "CubeAgentZone.Environment.EpisodeLength.sum": {
            "value": 1924.0,
            "min": 1703.0,
            "max": 2262.0,
            "count": 25
        },
        "CubeAgentZone.Step.mean": {
            "value": 49972.0,
            "min": 1989.0,
            "max": 49972.0,
            "count": 25
        },
        "CubeAgentZone.Step.sum": {
            "value": 49972.0,
            "min": 1989.0,
            "max": 49972.0,
            "count": 25
        },
        "CubeAgentZone.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.22183430194854736,
            "min": 0.0038324189372360706,
            "max": 0.35638588666915894,
            "count": 25
        },
        "CubeAgentZone.Policy.ExtrinsicValueEstimate.sum": {
            "value": 15.306567192077637,
            "min": 0.1379670798778534,
            "max": 24.23423957824707,
            "count": 25
        },
        "CubeAgentZone.Environment.CumulativeReward.mean": {
            "value": 0.30149253824753547,
            "min": 0.04444444510671827,
            "max": 0.4315789498780903,
            "count": 25
        },
        "CubeAgentZone.Environment.CumulativeReward.sum": {
            "value": 20.200000062584877,
            "min": 0.4000000059604645,
            "max": 26.800000086426735,
            "count": 25
        },
        "CubeAgentZone.Policy.ExtrinsicReward.mean": {
            "value": 0.30149253824753547,
            "min": 0.04444444510671827,
            "max": 0.4315789498780903,
            "count": 25
        },
        "CubeAgentZone.Policy.ExtrinsicReward.sum": {
            "value": 20.200000062584877,
            "min": 0.4000000059604645,
            "max": 26.800000086426735,
            "count": 25
        },
        "CubeAgentZone.Losses.PolicyLoss.mean": {
            "value": 0.2436938852634336,
            "min": 0.23208307336551587,
            "max": 0.2561536728650562,
            "count": 25
        },
        "CubeAgentZone.Losses.PolicyLoss.sum": {
            "value": 4.142796049478371,
            "min": 3.347411767598073,
            "max": 4.2854884570897225,
            "count": 25
        },
        "CubeAgentZone.Losses.ValueLoss.mean": {
            "value": 0.08026772360545142,
            "min": 0.0006818616493835271,
            "max": 0.08641493861199598,
            "count": 25
        },
        "CubeAgentZone.Losses.ValueLoss.sum": {
            "value": 1.3645513012926742,
            "min": 0.010909786390136433,
            "max": 1.4690539564039315,
            "count": 25
        },
        "CubeAgentZone.Policy.LearningRate.mean": {
            "value": 5.915745086941176e-06,
            "min": 5.915745086941176e-06,
            "max": 0.0002935996021334667,
            "count": 25
        },
        "CubeAgentZone.Policy.LearningRate.sum": {
            "value": 0.00010056766647799999,
            "min": 0.00010056766647799999,
            "max": 0.0044039940320020005,
            "count": 25
        },
        "CubeAgentZone.Policy.Epsilon.mean": {
            "value": 0.10197188235294118,
            "min": 0.10197188235294118,
            "max": 0.19786653333333332,
            "count": 25
        },
        "CubeAgentZone.Policy.Epsilon.sum": {
            "value": 1.733522,
            "min": 1.733522,
            "max": 2.9759320000000002,
            "count": 25
        },
        "CubeAgentZone.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005000000000000002,
            "count": 25
        },
        "CubeAgentZone.Policy.Beta.sum": {
            "value": 0.0085,
            "min": 0.007000000000000003,
            "max": 0.0085,
            "count": 25
        },
        "CubeAgentZone.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 25
        },
        "CubeAgentZone.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 25
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1713348346",
        "python_version": "3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Acer\\anaconda3\\envs\\MLAgents\\Scripts\\mlagents-learn config/CubeAgentZone.yaml --run-id=CubeAgentZone15Degrees --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1713349402"
    },
    "total": 1056.1632089,
    "count": 1,
    "self": 0.03501770000025317,
    "children": {
        "run_training.setup": {
            "total": 0.14081980000000005,
            "count": 1,
            "self": 0.14081980000000005
        },
        "TrainerController.start_learning": {
            "total": 1055.9873713999998,
            "count": 1,
            "self": 2.3856626999890977,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.5694415,
                    "count": 1,
                    "self": 10.5694415
                },
                "TrainerController.advance": {
                    "total": 1042.6662897000108,
                    "count": 50906,
                    "self": 2.3786178999971526,
                    "children": {
                        "env_step": {
                            "total": 850.671863900008,
                            "count": 50906,
                            "self": 691.9884304000154,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 157.14762239999092,
                                    "count": 50906,
                                    "self": 6.05377569997691,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 151.093846700014,
                                            "count": 50007,
                                            "self": 151.093846700014
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.5358111000017267,
                                    "count": 50906,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1041.5914849000003,
                                            "count": 50906,
                                            "is_parallel": true,
                                            "self": 452.23371660000055,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.001457399999999609,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0005756999999988466,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0008817000000007624,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0008817000000007624
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 589.3563108999997,
                                                    "count": 50906,
                                                    "is_parallel": true,
                                                    "self": 9.151344499995275,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 6.695731799990174,
                                                            "count": 50906,
                                                            "is_parallel": true,
                                                            "self": 6.695731799990174
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 538.4874635000125,
                                                            "count": 50906,
                                                            "is_parallel": true,
                                                            "self": 538.4874635000125
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 35.02177110000174,
                                                            "count": 50906,
                                                            "is_parallel": true,
                                                            "self": 18.694201000027544,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 16.3275700999742,
                                                                    "count": 203624,
                                                                    "is_parallel": true,
                                                                    "self": 16.3275700999742
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 189.61580790000562,
                            "count": 50906,
                            "self": 2.5121895000097254,
                            "children": {
                                "process_trajectory": {
                                    "total": 10.600153499996697,
                                    "count": 50906,
                                    "self": 10.600153499996697
                                },
                                "_update_policy": {
                                    "total": 176.5034648999992,
                                    "count": 398,
                                    "self": 21.520206100002298,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 154.9832587999969,
                                            "count": 14373,
                                            "self": 154.9832587999969
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.9999999949504854e-06,
                    "count": 1,
                    "self": 1.9999999949504854e-06
                },
                "TrainerController._save_models": {
                    "total": 0.3659754999998768,
                    "count": 1,
                    "self": 0.03994969999985187,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.3260258000000249,
                            "count": 1,
                            "self": 0.3260258000000249
                        }
                    }
                }
            }
        }
    }
}